{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01d2719e-3cfa-46a1-ac34-24cd07d5571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from typing import List, Tuple\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from spondee.search import nlp_pipeline, search_text, identify_statements, nounphrase_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5188743a-0ab4-4751-9777-bd2e759495c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafLabel(BaseModel):\n",
    "    id: int\n",
    "    text: str\n",
    "    upos: str\n",
    "    xpos: str\n",
    "    feats: str\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4821e7-fa7d-4d7b-ba54-9d7a97bea12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sentence_metadata(statements, simple_sentence:List[dict]):\n",
    "    paths = []\n",
    "    stack = statements\n",
    "    q = deque(simple_sentence)\n",
    "    while stack:\n",
    "        noun_phrase, verb_phrase = stack.pop()\n",
    "\n",
    "        npq = deque(noun_phrase.leaf_labels())\n",
    "        vpq = deque(verb_phrase.leaf_labels())\n",
    "\n",
    "        _np = []\n",
    "        _vp = []\n",
    "\n",
    "        while npq or vpq:\n",
    "            _leaf = q.popleft()\n",
    "\n",
    "            if npq and npq[0] == _leaf['text']:\n",
    "                _np.append(_leaf)\n",
    "                npq.popleft()\n",
    "\n",
    "            elif vpq and vpq[0] == _leaf['text']:\n",
    "                _vp.append(_leaf)\n",
    "                vpq.popleft()\n",
    "\n",
    "        paths.append((_np, _vp))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4096a9-28c5-4682-989e-fcd78db83a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 22:38:46 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb733738b5a401b8ba4bf3b2930bde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 22:38:46 INFO: Downloaded file to /Users/tylerbrown/stanza_resources/resources.json\n",
      "2024-07-06 22:38:46 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-07-06 22:38:47 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2024-07-06 22:38:47 INFO: Using device: cpu\n",
      "2024-07-06 22:38:47 INFO: Loading: tokenize\n",
      "2024-07-06 22:38:47 INFO: Loading: mwt\n",
      "2024-07-06 22:38:47 INFO: Loading: pos\n",
      "2024-07-06 22:38:47 INFO: Loading: constituency\n",
      "2024-07-06 22:38:47 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = nlp_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05546c74-ee98-4e58-a6a1-aa034193f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\".join(\n",
    "        [\n",
    "            \"Gavin Sheets hit his first career grand slam, and the \",\n",
    "            \"Chicago White Sox won their second straight after a \",\n",
    "            \"franchise-record 14-game losing streak, beating the \",\n",
    "            \"Boston Red Sox 6-1 on Saturday.\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4856763f-8056-42b8-b060-b77c51bc5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_text(txt, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "685e1e7a-14ec-41a0-b6f8-e30640105837",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce5fc1f-d19c-4463-999e-a77ef1838709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ROOT (S (S (NP (NNP Gavin) (NNP Sheets)) (VP (VBD hit) (NP (PRP$ his) (JJ first) (NN career) (JJ grand) (NN slam)))) (, ,) (CC and) (S (NP (DT the) (NNP Chicago) (NNP White) (NNPS Sox)) (VP (VBD won) (NP (PRP$ their) (JJ second) (NN straight)) (PP (IN after) (NP (DT a) (NML (NN franchise) (HYPH -) (NN record)) (NML (CD 14) (HYPH -) (NN game)) (NN losing) (NN streak))) (, ,) (S (VP (VBG beating) (NP (DT the) (NNP Boston) (NNP Red) (NNPS Sox)) (NP (NP (CD 6)) (PP (SYM -) (NP (CD 1)))) (PP (IN on) (NP (NNP Saturday))))))) (. .)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fed37-a2d6-44b0-9bbe-5a5f309b8e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7d4a674-aea4-4fa6-9bc8-cde5bd472935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = docs.sentences[0].constituency\n",
    "statements = identify_statements(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e75132-1bc8-4e3c-a8be-4f56df27426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_paths = simple_sentence_metadata(statements, docs.sentences[0].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70c7a0-5d51-4dea-afb4-ebfbd44df856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "732600be-3c2e-41cc-bf53-f12af3cfe687",
   "metadata": {},
   "outputs": [],
   "source": [
    "_node = statements[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c91103ab-aa1f-47e6-929d-6be4857d4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_label(node):\n",
    "    path = []\n",
    "    stack = [ node ]\n",
    "    prev_label = None\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if len(node.children) == 0:\n",
    "            path.append((prev_label, node.label))\n",
    "\n",
    "        stack.extend(node.children)\n",
    "        prev_label = node.label\n",
    "\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "def extract_noun_phrases(node):\n",
    "    paths = []\n",
    "    q = deque([ node ])\n",
    "    while q:\n",
    "        node = q.popleft()\n",
    "        if node.label == \"NP\":\n",
    "            paths.append(extract_node_label(node))\n",
    "\n",
    "        else:\n",
    "            q.extend(node.children)\n",
    "\n",
    "    return paths\n",
    "\n",
    "def filter_noun_phrases(extracted_np):\n",
    "    noun_tags = set([\"NN\", \"NNS\", \"NNP\", \"NNPS\"])\n",
    "    extract_tags = set([t for t, _ in extracted_np])\n",
    "\n",
    "    if len(noun_tags & extract_tags) == 0:\n",
    "        return None, False\n",
    "\n",
    "    first_tag, _ = extracted_np[0]\n",
    "    if first_tag == \"DT\" or first_tag[:3] == \"PRP\":\n",
    "        return extracted_np[1:], True\n",
    "\n",
    "    return extracted_np, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e45b5-d523-489d-9c4a-c7d41b5456c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1d286ce-8781-4800-8627-6eb8b152c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = []\n",
    "for extract in extract_noun_phrases(statements[0][1]):\n",
    "    tags, status = filter_noun_phrases(extract)\n",
    "    if status:\n",
    "        found.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57785a7c-2b18-4318-bf8a-ebf1704aa3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('JJ', 'second'), ('NN', 'straight')],\n",
       " [('NN', 'franchise'),\n",
       "  ('HYPH', '-'),\n",
       "  ('NN', 'record'),\n",
       "  ('CD', '14'),\n",
       "  ('HYPH', '-'),\n",
       "  ('NN', 'game'),\n",
       "  ('NN', 'losing'),\n",
       "  ('NN', 'streak')],\n",
       " [('NNP', 'Boston'), ('NNP', 'Red'), ('NNPS', 'Sox')],\n",
       " [('NNP', 'Saturday')]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb278db-3724-4387-96fb-4896d28741c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.leaf_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9a168-f45b-4b87-aa32-88bab40cd54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
