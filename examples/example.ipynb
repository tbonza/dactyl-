{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d2719e-3cfa-46a1-ac34-24cd07d5571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from typing import List, Tuple\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from spondee.search import nlp_pipeline, identify_statements\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5188743a-0ab4-4751-9777-bd2e759495c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafLabel(BaseModel):\n",
    "    id: int\n",
    "    text: str\n",
    "    upos: str\n",
    "    xpos: str\n",
    "    feats: str = Field(default=\"\")\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "    misc: str = Field(default=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91103ab-aa1f-47e6-929d-6be4857d4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_label(node):\n",
    "    path = []\n",
    "    stack = [ node ]\n",
    "    prev_label = None\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if len(node.children) == 0:\n",
    "            path.append((prev_label, node.label))\n",
    "\n",
    "        stack.extend(node.children)\n",
    "        prev_label = node.label\n",
    "\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "def extract_noun_phrases(node):\n",
    "    paths = []\n",
    "    q = deque([ node ])\n",
    "    while q:\n",
    "        node = q.popleft()\n",
    "        if node.label == \"NP\":\n",
    "            paths.append(extract_node_label(node))\n",
    "\n",
    "        else:\n",
    "            q.extend(node.children)\n",
    "\n",
    "    return paths\n",
    "\n",
    "def filter_noun_phrases(extracted_np):\n",
    "    noun_tags = set([\"NN\", \"NNS\", \"NNP\", \"NNPS\"])\n",
    "    extract_tags = set([t for t, _ in extracted_np])\n",
    "\n",
    "    if len(noun_tags & extract_tags) == 0:\n",
    "        return []\n",
    "\n",
    "    first_tag, _ = extracted_np[0]\n",
    "    if first_tag == \"DT\" or first_tag[:3] == \"PRP\":\n",
    "        return extracted_np[1:]\n",
    "\n",
    "    return extracted_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f48370-6511-4dee-95a0-21529b89593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nounphrase_metadata(npm, extract):\n",
    "    meta_q = deque(npm)\n",
    "    extract_q = deque(extract)\n",
    "\n",
    "    found = []\n",
    "    while extract_q:\n",
    "        tag, s = extract_q.popleft()\n",
    "        \n",
    "        while meta_q:\n",
    "            _meta = meta_q.popleft()\n",
    "            if _meta[\"xpos\"] == tag and _meta['text'] == s:\n",
    "                found.append(_meta)\n",
    "                break\n",
    "\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4821e7-fa7d-4d7b-ba54-9d7a97bea12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_metadata(statements, simple_sentence:List[dict]):\n",
    "    paths = []\n",
    "    stack = statements\n",
    "    q = deque(simple_sentence)\n",
    "    while stack:\n",
    "        noun_phrase, verb_phrase = stack.pop()\n",
    "\n",
    "        _tagged_np = [ filter_noun_phrases(r) for r in extract_noun_phrases(noun_phrase) ]        \n",
    "        _tagged_vp = [ filter_noun_phrases(r) for r in extract_noun_phrases(verb_phrase) ]\n",
    "\n",
    "        npq = deque(noun_phrase.leaf_labels())\n",
    "        vpq = deque(verb_phrase.leaf_labels())\n",
    "\n",
    "        _np = []\n",
    "        _vp = []\n",
    "\n",
    "        while npq or vpq:\n",
    "            _leaf = q.popleft()\n",
    "\n",
    "            if npq and npq[0] == _leaf['text']:\n",
    "                _np.append(_leaf)\n",
    "                npq.popleft()\n",
    "\n",
    "            elif vpq and vpq[0] == _leaf['text']:\n",
    "                _vp.append(_leaf)\n",
    "                vpq.popleft()\n",
    "\n",
    "        _found_np = []\n",
    "        for tagged in _tagged_np:\n",
    "            _meta = nounphrase_metadata(_np, tagged)\n",
    "            if len(_meta) > 0:\n",
    "                _found_np.append(_meta)\n",
    "\n",
    "        _found_vp = []\n",
    "        for tagged in _tagged_vp:\n",
    "            _meta = nounphrase_metadata(_vp, tagged)\n",
    "            if len(_meta) > 0:\n",
    "                _found_vp.append(_meta)\n",
    "            \n",
    "        paths.append((_np, _vp, _found_np, _found_vp))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4096a9-28c5-4682-989e-fcd78db83a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 00:45:08 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe11639fa564e91a81beb6c66e69bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 00:45:08 INFO: Downloaded file to /Users/tylerbrown/stanza_resources/resources.json\n",
      "2024-07-07 00:45:08 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-07-07 00:45:08 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2024-07-07 00:45:08 INFO: Using device: cpu\n",
      "2024-07-07 00:45:08 INFO: Loading: tokenize\n",
      "2024-07-07 00:45:09 INFO: Loading: mwt\n",
      "2024-07-07 00:45:09 INFO: Loading: pos\n",
      "2024-07-07 00:45:09 INFO: Loading: constituency\n",
      "2024-07-07 00:45:09 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = nlp_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05546c74-ee98-4e58-a6a1-aa034193f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\".join(\n",
    "        [\n",
    "            \"Gavin Sheets hit his first career grand slam, and the \",\n",
    "            \"Chicago White Sox won their second straight after a \",\n",
    "            \"franchise-record 14-game losing streak, beating the \",\n",
    "            \"Boston Red Sox 6-1 on Saturday.\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4856763f-8056-42b8-b060-b77c51bc5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_text(txt, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "685e1e7a-14ec-41a0-b6f8-e30640105837",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "058c41a1-2d9c-445f-a4e8-1cfe594a2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in docs.sentences:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "794fed37-a2d6-44b0-9bbe-5a5f309b8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d4a674-aea4-4fa6-9bc8-cde5bd472935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = docs.sentences[0].constituency\n",
    "statements = identify_statements(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e75132-1bc8-4e3c-a8be-4f56df27426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_paths = sentence_metadata(statements, docs.sentences[0].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c29fbe1-23d5-4652-bb77-d283c9083381",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LeafLabel\nfeats\n  Field required [type=missing, input_value={'id': 22, 'text': '-', '...'misc': 'SpaceAfter=No'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grp \u001b[38;5;129;01min\u001b[39;00m _paths[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m grp:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mLeafLabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/spondee-SzFmhREc-py3.11/lib/python3.11/site-packages/pydantic/main.py:568\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    567\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LeafLabel\nfeats\n  Field required [type=missing, input_value={'id': 22, 'text': '-', '...'misc': 'SpaceAfter=No'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "source": [
    "for grp in _paths[1][3]:\n",
    "    for m in grp:\n",
    "        LeafLabel.model_validate(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09da4650-4a95-479e-a4e6-6355824fe267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f14243ba-7566-4fd2-81a7-cd048ddc3070",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (1495596285.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    _paths[1][2][01\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "_paths[1][2]["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314dd45-964a-45ad-9378-baf1dfbb2148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "865d015a-8cc4-4f94-bbf2-8f43b8daf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp in _paths[1][3]:\n",
    "    for m in grp:\n",
    "        try:\n",
    "            LeafLabel.model_validate(m)\n",
    "        except Exception as exc:\n",
    "            print(m, exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de638e49-4977-48fa-9d0f-477f37b7f903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c027fb0-deeb-4b10-ac9d-1857b61b23bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
